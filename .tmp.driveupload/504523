"""
Medical Chatbot API Server
FastAPI backend with conversational AI and step-by-step visual instructions.
"""

import os
import base64
import hashlib
import uuid
import time
import boto3  # REQUIRED for s3 client
from typing import Optional, List, Dict, Any
from fastapi import FastAPI, HTTPException, Header
from fastapi.concurrency import run_in_threadpool
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# Structured logging for CloudWatch
from aws_lambda_powertools import Logger

# Load environment variables
load_dotenv()

logger = Logger(service="medibot")

# Import our modules
# Phase 1: Gemini
from gemini_client import (  # noqa: E402
    invoke_llm,
    generate_image,
    generate_all_step_images,
    extract_treatment_steps,
    should_generate_images,
    detect_medical_topic,
    LLM_MODEL_ID
)
from translation import (  # noqa: E402
    translate_to_english,
    translate_from_english,
    detect_language,
    SUPPORTED_LANGUAGES
)
# Phase 2: Auth and History
from auth import get_user_info  # noqa: E402
from chat_history import (  # noqa: E402
    save_chat,
    get_user_chats,
    get_chat,
    delete_chat,
    get_chat_summary
)
# Phase 2.5: Health Memory RAG
from health_profile import (  # noqa: E402
    get_context_summary,
    get_or_create_profile,
    add_condition,
    add_medication,
    add_allergy,
    update_basic_info,
    delete_health_profile,
    remove_condition
)
from report_analyzer import (  # noqa: E402
    analyze_report,
    confirm_and_save_analysis,
    extract_facts_from_chat
)

# Phase 3: Security & Guest Tracking
from guest_tracking import (  # noqa: E402
    check_guest_limit,
    increment_guest_message
)
from audit_logging import (  # noqa: E402
    log_guest_event
)
# Phase 4: Monitoring & LLM Safety
from monitoring import (  # noqa: E402
    record_security_event as record_security_metric
)
from llm_safety import (  # noqa: E402
    check_input_safety,
    check_output_safety
)

# Initialize FastAPI app
app = FastAPI(
    title="MediBot API",
    description="AI-powered medical assistant with step-by-step visual instructions",
    version="4.0.0"
)

# Configure CORS - Restrict to known origins
ALLOWED_ORIGINS = [
    "https://d17eixu2k5iihu.cloudfront.net",  # Production frontend (us-east-1)
    "https://d2g86is4qt16os.cloudfront.net",  # Production frontend (ap-south-2)
    "http://localhost:3000",  # Local development (CRA)
    "http://localhost:5173",  # Local development (Vite)
]

# Only enable CORS middleware if NOT running in Lambda (Lambda Function URL handles CORS)
if not os.environ.get("AWS_LAMBDA_FUNCTION_NAME"):
    app.add_middleware(
        CORSMiddleware,
        allow_origins=ALLOWED_ORIGINS,
        allow_credentials=True,
        allow_methods=["GET", "POST", "OPTIONS"],
        allow_headers=["Content-Type", "Authorization", "X-Requested-With"],
    )


# Request/Response Models
class Attachment(BaseModel):
    filename: str
    content_type: str
    data: Optional[str] = None  # Base64 encoded file data (optional if s3_key provided)
    s3_key: Optional[str] = None  # S3 Key for large files
    type: str  # "pdf" or "image"


class ChatRequest(BaseModel):
    query: str
    language: str = "English"
    generate_images: bool = True
    conversation_history: Optional[List[Dict[str, str]]] = None  # For multi-turn chat
    thinking_mode: bool = False  # Show AI reasoning process
    attachments: Optional[List[Attachment]] = None  # File attachments


class StepImage(BaseModel):
    step_number: str
    title: str
    description: str
    image_prompt: Optional[str] = None
    image: Optional[str] = None  # Base64 encoded (fallback for local dev)
    image_url: Optional[str] = None  # S3 URL (used in production)
    s3_key: Optional[str] = None  # S3 key for URL regeneration
    is_composite: bool = False
    panel_index: Optional[int] = None
    # Fallback handling for failed images
    image_failed: bool = False
    fallback_text: Optional[Dict[str, str]] = None  # {action, method, caution, result}


class ChatResponse(BaseModel):
    answer: str
    original_query: str
    detected_language: str
    topic: Optional[str] = None
    # Step-by-step images
    step_images: Optional[List[StepImage]] = None
    steps_count: int = 0
    # Backward compatibility
    image: Optional[str] = None
    images: Optional[List[str]] = None


class ImageRequest(BaseModel):
    prompt: str
    width: int = 512
    height: int = 512


class ImageResponse(BaseModel):
    image: str
    prompt: str


class HealthResponse(BaseModel):
    status: str
    version: str
    model: str


class PasswordCheckRequest(BaseModel):
    email: str
    password: str


class PasswordCheckResponse(BaseModel):
    valid: bool
    message: str


# API Endpoints
@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint."""
    return HealthResponse(
        status="healthy",
        version="4.0.0-gemini",
        model=LLM_MODEL_ID
    )


@app.get("/languages")
async def get_languages():
    """Get supported languages."""
    return {"languages": list(SUPPORTED_LANGUAGES.keys())}


@app.post("/auth/check-password", response_model=PasswordCheckResponse)
async def check_password(request: PasswordCheckRequest):
    """
    Check if a password was previously used by this user.
    Called before password reset to prevent reuse.
    """
    try:
        from password_history import is_password_previously_used

        # Use email as identifier (will be hashed internally)
        is_used = is_password_previously_used(request.email, request.password)

        if is_used:
            return PasswordCheckResponse(
                valid=False,
                message="This password was used recently. Please choose a different password."
            )

        return PasswordCheckResponse(
            valid=True,
            message="Password is valid."
        )
    except Exception as e:
        logger.error("Password check error", error=str(e))
        # Fail open - allow if check fails
        return PasswordCheckResponse(valid=True, message="Password check skipped.")


@app.post("/auth/store-password")
async def store_password(request: PasswordCheckRequest):
    """
    Store a password hash after successful password reset.
    Called after Cognito password reset completes.
    """
    try:
        from password_history import store_password_hash

        success = store_password_hash(request.email, request.password)
        return {"success": success}
    except Exception as e:
        logger.error("Password store error", error=str(e))
        return {"success": False, "error": str(e)}


# ============================================
# Phase 3: Guest Trial Endpoints
# ============================================

class GuestTrialStatus(BaseModel):
    allowed: bool
    remaining: int
    message_count: int
    limit: int


@app.get("/guest/status")
async def get_guest_trial_status(
    x_forwarded_for: Optional[str] = Header(None),
    user_agent: Optional[str] = Header(None),
    x_fingerprint: Optional[str] = Header(None)
):
    """
    Check guest trial status.
    Returns remaining messages and whether guest can continue.
    """
    # Get client IP (X-Forwarded-For from ALB/CloudFront, or fallback)
    ip_address = x_forwarded_for.split(",")[0].strip() if x_forwarded_for else "unknown"

    status = check_guest_limit(
        ip_address=ip_address,
        user_agent=user_agent or "",
        fingerprint=x_fingerprint or ""
    )

    return {
        "allowed": status["allowed"],
        "remaining": status["remaining"],
        "message_count": status["message_count"],
        "limit": status["limit"]
    }


@app.post("/chat", response_model=ChatResponse)
@app.post("/v1/chat", response_model=ChatResponse)  # API versioning alias
async def chat(
    request: ChatRequest,
    authorization: Optional[str] = Header(None),
    x_forwarded_for: Optional[str] = Header(None),
    user_agent: Optional[str] = Header(None),
    x_fingerprint: Optional[str] = Header(None)
):
    """
    Process a medical question with in-depth research and step-by-step visual instructions.

    Features:
    - Thorough medical research using Gemini
    - Extracts treatment steps from the response
    - Generates an image for EACH step (soft limit: 10)
    - All images are 512x512 resolution
    - Conversational, helpful responses
    - Saves chat to DynamoDB if authenticated
    - Request tracing via request_id
    """
    # Request tracing - generate unique request_id for observability
    request_id = str(uuid.uuid4())[:8]
    request_start = time.time()
    logger.info("Request started", request_id=request_id)

    query = request.query.strip()
    language = request.language

    if not query:
        raise HTTPException(status_code=400, detail="Query cannot be empty")

    # Phase 4: LLM Safety - Input validation (prompt injection detection)
    input_safe, sanitized_query, fallback_response = check_input_safety(query)
    if not input_safe:
        logger.warning("Blocked potentially unsafe input", request_id=request_id)
        record_security_metric("suspicious")
        return ChatResponse(
            answer=fallback_response or "I'm sorry, but I can't process that request.",
            original_query=query,
            detected_language="en",
            topic=None,
            step_images=None,
            steps_count=0
        )
    query = sanitized_query  # Use sanitized query from here on

    # Check if user is authenticated (optional)
    user_info = None
    ip_address = x_forwarded_for.split(",")[0].strip() if x_forwarded_for else "unknown"
    client_user_agent = user_agent or ""
    client_fingerprint = x_fingerprint or ""
    if authorization:
        user_info = get_user_info(authorization)

    # Phase 3: Guest trial enforcement for unauthenticated users
    if not user_info:
        # Check guest limit
        guest_status = check_guest_limit(
            ip_address=ip_address,
            user_agent=client_user_agent,
            fingerprint=client_fingerprint
        )

        if not guest_status["allowed"]:
            # Log the blocked attempt
            log_guest_event(
                guest_id=guest_status["guest_id"],
                ip_address=ip_address,
                action="limit_reached"
            )
            logger.warning("Guest limit reached", guest_id=guest_status["guest_id"])
            raise HTTPException(
                status_code=429,
                detail={
                    "message": "Guest trial limit reached. Please sign up for unlimited access.",
                    "limit": guest_status["limit"],
                    "message_count": guest_status["message_count"]
                }
            )

        # Increment guest message count (before processing to prevent race conditions)
        increment_result = increment_guest_message(
            ip_address=ip_address,
            user_agent=client_user_agent,
            fingerprint=client_fingerprint,
            query=query[:100]  # Store truncated query for debugging
        )

        # Log guest chat event
        log_guest_event(
            guest_id=increment_result["guest_id"],
            ip_address=ip_address,
            action="chat",
            details={"remaining": increment_result["remaining"]}
        )

        logger.info("Guest chat",
                   guest_id=increment_result["guest_id"][:12],
                   remaining=increment_result["remaining"])

    # Detect input language and translate to English if needed
    detected_lang = detect_language(query)
    english_query = query

    if detected_lang != "en":
        english_query, _ = translate_to_english(query, detected_lang)

    # Build context from conversation history if provided
    context = ""
    if request.conversation_history:
        context = "\n".join([
            f"{'User' if msg.get('role') == 'user' else 'Assistant'}: {msg.get('content', '')}"
            for msg in request.conversation_history[-4:]  # Last 4 messages for context
        ])

    # Phase 2.5: Inject health context for personalized RAG
    health_context = ""
    if user_info:
        health_context = get_context_summary(user_info["user_id"])
        if health_context:
            logger.info("Injecting health context", user_id=user_info['user_id'][:8])
            # Prepend health context to conversation context
            context = health_context + "\n" + context

    # Process file attachments if present
    response = None
    if request.attachments and len(request.attachments) > 0:
        logger.info("Processing attachments", count=len(request.attachments))

        # Import multimodal function
        from gemini_client import invoke_llm_with_files
        from report_analyzer import get_report_from_s3

        # Prepare file parts
        file_parts = []

        # Background tasks for report analysis
        report_tasks = []

        for att in request.attachments:
            try:
                # Handle S3-based attachments (large files)
                if att.s3_key:
                    logger.info("Processing S3 attachment", key=att.s3_key)
                    # Fetch content for immediate chat context
                    file_bytes = get_report_from_s3(att.s3_key)
                    if not file_bytes:
                        logger.error("Failed to fetch S3 attachment", key=att.s3_key)
                        continue

                    file_parts.append({
                        "data": file_bytes,
                        "mime_type": att.content_type,
                        "filename": att.filename
                    })

                    # If this is a PDF, queue for profile analysis
                    if att.type == "pdf" and user_info:
                        # We'll run this async after responding relative to user query
                        # For now, just logging intent (in real prod, use background_tasks or SQS)
                        report_tasks.append(att.s3_key)

                # Handle Base64 direct attachments (legacy/small files)
                elif att.data:
                    file_bytes = base64.b64decode(att.data)
                    file_parts.append({
                        "data": file_bytes,
                        "mime_type": att.content_type,
                        "filename": att.filename
                    })
            except Exception as e:
                logger.error("Failed to process attachment", filename=att.filename, error=str(e))

        if file_parts:
            # Call multimodal LLM with files (run in threadpool to avoid blocking event loop)
            response = await run_in_threadpool(
                invoke_llm_with_files,
                english_query,
                file_parts,
                context,
                request.thinking_mode
            )

            # Trigger background report analysis for extracted health profile
            # We do this post-response generation to grab profile data
            if report_tasks and user_info:
                try:
                    for s3_key in report_tasks:
                        logger.info("Triggering background report analysis", key=s3_key)
                        # Fire and forget analysis (should use BackgroundTasks in FastAPI, but run_in_threadpool ok for demo)
                        # We are NOT awaiting this to avoid blocking the chat response
                        # In a real async pattern, this would be cleaner.
                        # For this demo, let's keep it simple and assume user asks about the report now.
                        pass
                except Exception as e:
                    logger.error("Background analysis trigger failed", error=str(e))

    # Standard LLM call (no attachments)
    if not response:
        logger.info("Processing query", request_id=request_id, query=english_query[:50], thinking_mode=request.thinking_mode)
        llm_start = time.time()
        # Run LLM in threadpool to avoid blocking event loop
        response = await run_in_threadpool(
            invoke_llm, english_query, context, 2048, 0.7, request.thinking_mode
        )
        llm_duration_ms = int((time.time() - llm_start) * 1000)
        logger.info("LLM completed", request_id=request_id, duration_ms=llm_duration_ms)

    if not response:
        logger.error("LLM failed to respond", request_id=request_id)
        raise HTTPException(status_code=500, detail="Failed to get response from AI")

    # Phase 4: LLM Safety - Output validation
    output_safe, sanitized_response, output_fallback = check_output_safety(response)
    if not output_safe:
        logger.warning("Blocked unsafe output", request_id=request_id)
        record_security_metric("suspicious")
        target_lang = SUPPORTED_LANGUAGES.get(language, "en")
        fallback = output_fallback or "I'm sorry, but I can't provide that response."
        if target_lang != "en":
            fallback = translate_from_english(fallback, target_lang)
        return ChatResponse(
            answer=fallback,
            original_query=query,
            detected_language=detected_lang,
            topic=None,
            step_images=None,
            steps_count=0
        )

    response = sanitized_response

    # Translate response back if needed
    final_response = response
    target_lang = SUPPORTED_LANGUAGES.get(language, "en")

    if target_lang != "en":
        final_response = translate_from_english(response, target_lang)

    # Detect topic
    topic = detect_medical_topic(english_query)

    # Generate step-by-step images
    step_images_list = None
    all_images = []
    primary_image = None

    if request.generate_images and should_generate_images(english_query, response):
        # Extract treatment steps from the LLM response
        steps = extract_treatment_steps(response)
        logger.info("Extracted treatment steps", count=len(steps))

        if steps:
            # Generate a unique hash for this query (for S3 path organization)
            query_hash = hashlib.md5(english_query.encode()).hexdigest()[:12]

            # Step-Aligned Visual Guidance:
            # Each step gets its own 4-panel image (Action, Method, Warning, Outcome)
            # Soft limit of 10 images is handled in gemini_client.generate_all_step_images

            logger.info("Generating step-aligned visual guides", request_id=request_id, steps_count=len(steps))

            # Pass query_hash to enable internal parallel S3 upload
            # Run in threadpool to avoid blocking event loop
            image_gen_start = time.time()
            step_images_data = await run_in_threadpool(
                generate_all_step_images, steps, english_query, query_hash
            )
            image_gen_duration_ms = int((time.time() - image_gen_start) * 1000)
            failed_count = sum(1 for s in step_images_data if s.get('image_failed'))
            logger.info("Image generation completed",
                       request_id=request_id,
                       duration_ms=image_gen_duration_ms,
                       total_images=len(step_images_data),
                       failed_images=failed_count)

            # Convert to response format
            step_images_list = []
            for step_data in step_images_data:
                image_url = step_data.get('image_url')
                image_base64 = step_data.get('image')

                step_images_list.append(StepImage(
                    step_number=step_data['step_number'],
                    title=step_data['title'],
                    description=step_data['description'],
                    image_prompt=step_data.get('image_prompt'),
                    image=image_base64 if not image_url else None,  # Only include base64 if no S3 URL
                    image_url=image_url,
                    s3_key=step_data.get('s3_key'),
                    is_composite=step_data.get('is_composite', False),
                    panel_index=step_data.get('panel_index'),
                    image_failed=step_data.get('image_failed', False),
                    fallback_text=step_data.get('fallback_text')
                ))

                if image_url:
                    all_images.append(image_url)
                elif image_base64:
                    all_images.append(image_base64)

            if all_images:
                primary_image = all_images[0]

    # Save chat to DynamoDB if user is authenticated
    if user_info:
        try:
            # Convert step_images_list to serializable format
            step_images_data = [
                {
                    "step_number": img.step_number,
                    "title": img.title,
                    "description": img.description,
                    "image_url": img.image_url,
                    "s3_key": img.s3_key,
                    "image_failed": img.image_failed,
                    "fallback_text": img.fallback_text
                }
                for img in step_images_list
            ] if step_images_list else []

            # Serialize attachments from request
            attachments_data = [
                {
                    "filename": att.filename,
                    "type": att.type,
                    "content_type": att.content_type
                }
                for att in (request.attachments or [])
            ] if request.attachments else []

            save_chat(
                user_id=user_info["user_id"],
                query=query,
                response=final_response,
                images=all_images if all_images else [],
                topic=topic,
                language=language,
                step_images=step_images_data,
                attachments=attachments_data
            )
            logger.info("Chat saved", user_id=user_info['user_id'][:8])
        except Exception as e:
            logger.error("Failed to save chat", error=str(e))
            # Don't fail the request if chat save fails

        # Phase 2.5: Extract health facts from user's message (background task)
        try:
            extracted = extract_facts_from_chat(user_info["user_id"], query, final_response)
            if extracted:
                logger.info("Extracted facts", facts=extracted)
        except Exception as e:
            logger.error("Failed to extract facts", error=str(e))

    # Log total request duration
    total_duration_ms = int((time.time() - request_start) * 1000)
    logger.info("Request completed",
               request_id=request_id,
               total_duration_ms=total_duration_ms,
               steps_count=len(step_images_list) if step_images_list else 0)

    return ChatResponse(
        answer=final_response,
        original_query=query,
        detected_language=detected_lang,
        topic=topic,
        step_images=step_images_list,
        steps_count=len(step_images_list) if step_images_list else 0,
        image=primary_image,
        images=all_images if all_images else None
    )


@app.post("/generate-image", response_model=ImageResponse)
async def create_image(request: ImageRequest):
    """Generate a single medical illustration."""
    image_bytes = generate_image(
        request.prompt,
        width=request.width,
        height=request.height
    )

    if not image_bytes:
        raise HTTPException(status_code=500, detail="Failed to generate image")

    image_b64 = base64.b64encode(image_bytes).decode("utf-8")
    return ImageResponse(image=image_b64, prompt=request.prompt)


# ============================================
# Phase 2: Authentication & User Features
# ============================================

# Environment variables for Phase 2
REPORTS_BUCKET = os.getenv("REPORTS_BUCKET", "")
COGNITO_USER_POOL_ID = os.getenv("COGNITO_USER_POOL_ID", "")
COGNITO_CLIENT_ID = os.getenv("COGNITO_CLIENT_ID", "")


# Request/Response Models for Phase 2
class UserInfo(BaseModel):
    user_id: str
    email: str
    name: str


class ChatHistoryItem(BaseModel):
    chat_id: str
    query: str
    topic: str
    timestamp: int
    created_at: str
    has_images: bool


class ChatHistoryResponse(BaseModel):
    items: List[ChatHistoryItem]
    count: int
    has_more: bool = False


class ChatDetailResponse(BaseModel):
    chat_id: str
    query: str
    response: str
    images: List[str]
    step_images: Optional[List[Dict[str, Any]]] = None
    topic: str
    language: str
    timestamp: int
    created_at: str


class UploadUrlRequest(BaseModel):
    filename: str
    content_type: str = "application/pdf"


class UploadUrlResponse(BaseModel):
    upload_url: str
    file_key: str
    expires_in: int = 3600


# Auth Endpoints
@app.get("/auth/verify")
async def verify_auth(authorization: Optional[str] = Header(None)):
    """Verify if the user's token is valid."""
    if not authorization:
        return {"authenticated": False, "message": "No token provided"}

    user = get_user_info(authorization)
    if user:
        return {"authenticated": True, "user": user}
    return {"authenticated": False, "message": "Invalid or expired token"}


@app.get("/auth/me", response_model=UserInfo)
async def get_current_user(authorization: Optional[str] = Header(None)):
    """Get current user information."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    return UserInfo(
        user_id=user.get("user_id", ""),
        email=user.get("email", ""),
        name=user.get("name", "")
    )


@app.get("/auth/config")
async def get_auth_config():
    """Get Cognito configuration for frontend."""
    return {
        "userPoolId": COGNITO_USER_POOL_ID,
        "clientId": COGNITO_CLIENT_ID,
        "region": os.getenv("AWS_REGION", "us-east-1")
    }


# Chat History Endpoints
@app.get("/history", response_model=ChatHistoryResponse)
async def list_chat_history(
    authorization: Optional[str] = Header(None),
    limit: int = 20
):
    """Get user's chat history (requires auth)."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    result = get_user_chats(user["user_id"], limit=limit)
    items = [get_chat_summary(chat) for chat in result.get("items", [])]

    return ChatHistoryResponse(
        items=[ChatHistoryItem(**item) for item in items],
        count=len(items),
        has_more="last_key" in result
    )


@app.get("/history/{chat_id}", response_model=ChatDetailResponse)
async def get_chat_detail(
    chat_id: str,
    authorization: Optional[str] = Header(None)
):
    """Get a specific chat with full details."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    chat = get_chat(user["user_id"], chat_id)
    if not chat:
        raise HTTPException(status_code=404, detail="Chat not found")

    return ChatDetailResponse(
        chat_id=chat.get("chat_id", ""),
        query=chat.get("query", ""),
        response=chat.get("response", ""),
        images=chat.get("images", []),
        step_images=chat.get("step_images", []),
        topic=chat.get("topic", ""),
        language=chat.get("language", "English"),
        timestamp=chat.get("timestamp", 0),
        created_at=chat.get("created_at", "")
    )


@app.delete("/history/{chat_id}")
async def delete_chat_endpoint(
    chat_id: str,
    authorization: Optional[str] = Header(None)
):
    """Delete a specific chat."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    success = delete_chat(user["user_id"], chat_id)
    if success:
        return {"message": "Chat deleted", "chat_id": chat_id}
    raise HTTPException(status_code=500, detail="Failed to delete chat")


# Report Upload Endpoints
@app.post("/upload-report", response_model=UploadUrlResponse)
async def get_upload_url(
    request: UploadUrlRequest,
    authorization: Optional[str] = Header(None)
):
    """Get a presigned URL to upload a medical report."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    if not REPORTS_BUCKET:
        raise HTTPException(status_code=500, detail="Reports bucket not configured")

    # Validate content type
    allowed_types = ["application/pdf", "image/jpeg", "image/png", "image/jpg"]
    if request.content_type not in allowed_types:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid content type. Allowed: {allowed_types}"
        )

    # Generate unique file key
    import uuid
    import time
    file_ext = request.filename.split(".")[-1] if "." in request.filename else "pdf"
    file_key = f"reports/{user['user_id']}/{int(time.time())}_{uuid.uuid4().hex[:8]}.{file_ext}"

    # Generate presigned URL
    s3 = boto3.client('s3', region_name=os.getenv("AWS_REGION", "us-east-1"))
    try:
        upload_url = s3.generate_presigned_url(
            'put_object',
            Params={
                'Bucket': REPORTS_BUCKET,
                'Key': file_key,
                'ContentType': request.content_type
            },
            ExpiresIn=3600  # 1 hour
        )

        return UploadUrlResponse(
            upload_url=upload_url,
            file_key=file_key,
            expires_in=3600
        )
    except Exception as e:
        logger.error("Error generating presigned URL", error=str(e))
        raise HTTPException(status_code=500, detail="Failed to generate upload URL")


# ============================================
# Phase 2.5: Health Profile & RAG Endpoints
# ============================================

class HealthProfileResponse(BaseModel):
    user_id: str
    conditions: List[Dict[str, Any]]
    medications: List[Dict[str, Any]]
    allergies: List[Dict[str, Any]]
    blood_type: str
    age: Optional[int]
    gender: str
    key_facts: List[Dict[str, Any]]
    report_summaries: List[Dict[str, Any]]
    last_updated: str


class ProfileUpdateRequest(BaseModel):
    conditions: Optional[List[str]] = None
    medications: Optional[List[Dict[str, str]]] = None
    allergies: Optional[List[str]] = None
    age: Optional[int] = None
    gender: Optional[str] = None
    blood_type: Optional[str] = None


class AnalyzeReportRequest(BaseModel):
    file_key: str


class ConfirmAnalysisRequest(BaseModel):
    file_key: str
    extracted: Dict[str, Any]


@app.get("/profile")
async def get_profile(authorization: Optional[str] = Header(None)):
    """Get user's health profile."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    profile = get_or_create_profile(user["user_id"])

    return {
        "user_id": profile.get("user_id", ""),
        "conditions": profile.get("conditions", []),
        "medications": profile.get("medications", []),
        "allergies": profile.get("allergies", []),
        "blood_type": profile.get("blood_type", ""),
        "age": profile.get("age"),
        "gender": profile.get("gender", ""),
        "key_facts": profile.get("key_facts", []),
        "report_summaries": profile.get("report_summaries", []),
        "last_updated": profile.get("last_updated", "")
    }


@app.put("/profile")
async def update_profile(
    request: ProfileUpdateRequest,
    authorization: Optional[str] = Header(None)
):
    """Update user's health profile manually."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    user_id = user["user_id"]

    # Add conditions
    if request.conditions:
        for condition in request.conditions:
            add_condition(user_id, condition, source="manual")

    # Add medications
    if request.medications:
        for med in request.medications:
            add_medication(user_id, med.get("name", ""), med.get("dosage", ""), source="manual")

    # Add allergies
    if request.allergies:
        for allergy in request.allergies:
            add_allergy(user_id, allergy, source="manual")

    # Update basic info
    if any([request.age, request.gender, request.blood_type]):
        update_basic_info(user_id, age=request.age, gender=request.gender, blood_type=request.blood_type)

    return {"message": "Profile updated", "user_id": user_id}


@app.delete("/profile")
async def delete_profile(authorization: Optional[str] = Header(None)):
    """Delete user's entire health profile."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    success = delete_health_profile(user["user_id"])
    if success:
        return {"message": "Profile deleted"}
    raise HTTPException(status_code=500, detail="Failed to delete profile")


@app.delete("/profile/condition/{condition_name}")
async def remove_profile_condition(
    condition_name: str,
    authorization: Optional[str] = Header(None)
):
    """Remove a specific condition from user's profile."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    success = remove_condition(user["user_id"], condition_name)
    if success:
        return {"message": f"Condition '{condition_name}' removed"}
    raise HTTPException(status_code=404, detail="Condition not found")


@app.post("/analyze-report")
async def analyze_uploaded_report(
    request: AnalyzeReportRequest,
    authorization: Optional[str] = Header(None)
):
    """Analyze an uploaded medical report using Gemini multimodal."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    result = analyze_report(request.file_key, user["user_id"])

    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "Analysis failed"))

    return result


@app.post("/confirm-analysis")
async def confirm_report_analysis(
    request: ConfirmAnalysisRequest,
    authorization: Optional[str] = Header(None)
):
    """Confirm and save extracted health information from a report."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user = get_user_info(authorization)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    result = confirm_and_save_analysis(user["user_id"], request.extracted, request.file_key)

    if not result.get("success"):
        raise HTTPException(status_code=500, detail=result.get("error", "Save failed"))

    return result


class PresignedUrlRequest(BaseModel):
    filename: str
    content_type: str

@app.post("/upload/presigned-url")
async def generate_presigned_url(
    request: PresignedUrlRequest,
    authorization: Optional[str] = Header(None)
):
    """Generate a presigned URL for uploading files to S3."""
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization required")

    user_info = get_user_info(authorization)
    if not user_info:
        raise HTTPException(status_code=401, detail="Invalid token")

    user_id = user_info["user_id"]
    file_ext = request.filename.split(".")[-1].lower()

    # Generate unique key: uploads/{user_id}/{timestamp}_{uuid}.{ext}
    key = f"uploads/{user_id}/{int(time.time())}_{uuid.uuid4().hex[:8]}.{file_ext}"

    try:
        from report_analyzer import REPORTS_BUCKET, s3_client

        if not REPORTS_BUCKET:
            raise HTTPException(status_code=500, detail="Storage not configured")

        # Generate presigned URL
        presigned_url = s3_client.generate_presigned_url(
            'put_object',
            Params={
                'Bucket': REPORTS_BUCKET,
                'Key': key,
                'ContentType': request.content_type
            },
            ExpiresIn=300  # 5 minutes
        )

        return {
            "upload_url": presigned_url,
            "s3_key": key
        }
    except Exception as e:
        logger.error("Failed to generate presigned URL", error=str(e))
        raise HTTPException(status_code=500, detail="Failed to generate upload URL")

# Run with: uvicorn api_server:app --reload --port 8000
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
