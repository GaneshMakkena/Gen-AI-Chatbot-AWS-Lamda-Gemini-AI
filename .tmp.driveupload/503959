"""
Gemini Client - Using Google's NEW genai SDK for both LLM and Image generation.
Model: gemini-2.5-flash-image supports both text and image output.
"""

import os
import base64
import re
import uuid
import boto3
import concurrent.futures
from typing import Optional, Dict, Any, List

# NEW SDK - google-genai (not google-generativeai)
from google import genai
from dotenv import load_dotenv

# Structured logging
from aws_lambda_powertools import Logger

# Load environment variables
load_dotenv()

logger = Logger(service="medibot")

# Configuration
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
AWS_REGION = os.getenv("AWS_REGION", "us-east-1")

# Model IDs
LLM_MODEL_ID = os.getenv("GEMINI_LLM_MODEL", "gemini-2.5-pro")
IMAGE_MODEL_ID = "gemini-2.5-flash-image"  # Supports native image generation

# S3 bucket for storing generated images
IMAGES_BUCKET = os.getenv("IMAGES_BUCKET", "")

# Initialize Gemini client
client = None
if GOOGLE_API_KEY:
    client = genai.Client(api_key=GOOGLE_API_KEY)

# S3 client (initialized lazily)
_s3_client = None

def get_s3_client():
    """Get or create S3 client."""
    global _s3_client
    if _s3_client is None:
        _s3_client = boto3.client('s3', region_name=AWS_REGION)
    return _s3_client


def upload_image_to_s3(image_bytes: bytes, step_number: str, query_hash: str) -> tuple[Optional[str], Optional[str]]:
    """Upload image bytes to S3 and return (presigned_url, s3_key)."""
    if not IMAGES_BUCKET:
        logger.warning("IMAGES_BUCKET not configured")
        return None, None

    try:
        image_key = f"steps/{query_hash}/step_{step_number}_{uuid.uuid4().hex[:8]}.png"

        s3 = get_s3_client()
        s3.put_object(
            Bucket=IMAGES_BUCKET,
            Key=image_key,
            ContentType='image/png',
            Body=image_bytes
        )

        # Generate URL valid for 7 days (max practical for S3)
        presigned_url = s3.generate_presigned_url(
            'get_object',
            Params={'Bucket': IMAGES_BUCKET, 'Key': image_key},
            ExpiresIn=604800  # 7 days
        )
        logger.info("Uploaded image to S3", key=image_key)
        return presigned_url, image_key

    except Exception as e:
        logger.error("Error uploading to S3", error=str(e))
        return None, None


def clean_llm_response(response: str, keep_thinking: bool = False) -> str:
    """Clean the LLM response by optionally removing thinking tags."""
    if not response:
        return response

    if not keep_thinking:
        # Remove thinking tags if user doesn't want to see them
        cleaned = re.sub(r'<thinking>.*?</thinking>', '', response, flags=re.DOTALL)
    else:
        # Format thinking sections nicely for display
        cleaned = re.sub(r'<thinking>', '\n\n---\n**üß† My Thinking Process:**\n', response)
        cleaned = re.sub(r'</thinking>', '\n\n---\n\n', cleaned)

    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
    return cleaned.strip()


def invoke_llm(
    prompt: str,
    context: str = "",
    max_tokens: int = 2048,
    temperature: float = 0.7,
    thinking_mode: bool = False
) -> Optional[str]:
    """
    Invoke Gemini for medical research and treatment instructions.

    Args:
        prompt: User's query
        context: Additional context
        max_tokens: Maximum tokens in response
        temperature: Creativity level (0-1)
        thinking_mode: If True, show the model's reasoning process
    """

    if not client:
        logger.error("Gemini client not initialized - missing API key")
        return None

    # Formal Medical Assistance System Prompt (Production-Grade)
    system_prompt = """You are a medical assistance AI designed to provide step-by-step guidance for non-professional users.

## Your Responsibilities:

1. Generate clear, sequential medical assistance steps.
   - There is NO LIMIT on the number of steps.
   - Steps must be numbered explicitly from Step 1 to Step N.
   - Each step must be self-contained and unambiguous.

2. Each step must be suitable for visual explanation.
   - Avoid vague instructions.
   - Avoid compound actions in a single step.
   - Be specific about what, how, and where.

3. Each generated step will be paired with exactly one image.
   - Step i corresponds to Image i.
   - Do NOT reference images in your text output.

4. Internally structure each step so it can be visually expanded into:
   - What to do (primary action)
   - How to do it (method/technique)
   - What to avoid (common mistakes/warnings)
   - Expected outcome (confirmation of success)

5. Maintain medical safety:
   - Use non-invasive, general guidance only.
   - NEVER diagnose conditions.
   - NEVER prescribe medications.
   - Encourage professional care when risk is high.

6. If uncertainty exists:
   - Prefer clarity over brevity.
   - Add cautionary phrasing where appropriate.

## Response Format:

**Understanding Your Situation**
Brief explanation of the condition/problem

**Step-by-Step Treatment Guide**

**Step 1: [Clear Action Title]**
Detailed instruction (what to do, how, materials needed, timing)

**Step 2: [Clear Action Title]**
Detailed instruction...

(Continue for ALL necessary steps)

**‚ö†Ô∏è Important Warnings**
Critical safety information, contraindications

**When to Seek Professional Help**
Conditions that require immediate medical attention

## Guidelines:
- Be warm, reassuring, and conversational
- Explain WHY each step is important
- Use simple language anyone can understand
- Be specific about materials and timing
- Never skip steps due to assumed knowledge

7. Handling Greetings & Generic Inputs:
   - If the user says "Hi", "Hello", or is vague:
   - Respond warmly.
   - Summarize your capabilities (medical guides, steps, visuals).
   - Ask specifically what medical concern they have.
   - DO NOT generate a medical guide for a random condition (like burns or CPR) unless explicitly asked."""

    # Add thinking mode instruction if enabled
    if thinking_mode:
        system_prompt += """

## Thinking Mode (ENABLED)
Before providing your response, you MUST first show your reasoning process inside <thinking></thinking> tags.
Think through:
- What is the user asking?
- What medical knowledge applies here?
- What are the key safety considerations?
- What's the best way to structure the response?

Example:
<thinking>
The user is asking about [User's Specific Topic]...
Key considerations: [Safety, Method, Outcome]...
I should structure this with immediate first aid, then ongoing care...
</thinking>

Then provide your actual response after the thinking section."""

    try:
        full_prompt = f"Context: {context}\n\n{prompt}" if context else prompt
        combined_prompt = f"{system_prompt}\n\nUser: {full_prompt}"

        logger.info("Calling Gemini LLM", model=LLM_MODEL_ID, thinking_mode=thinking_mode)

        response = client.models.generate_content(
            model=LLM_MODEL_ID,
            contents=combined_prompt,
        )

        # Extract text from response
        response_text = None
        if response.text:
            response_text = response.text
        elif response.parts:
            for part in response.parts:
                if hasattr(part, 'text') and part.text:
                    response_text = part.text
                    break

        if response_text:
            return clean_llm_response(response_text, keep_thinking=thinking_mode)

        return None

    except Exception as e:
        logger.error("Error invoking Gemini LLM", error=str(e))
        import traceback
        print(traceback.format_exc())
        return None


def invoke_llm_with_files(
    prompt: str,
    files: List[Dict[str, Any]],
    context: str = "",
    thinking_mode: bool = False
) -> Optional[str]:
    """
    Invoke Gemini with file attachments (PDFs, images).

    Args:
        prompt: User's query
        files: List of dicts with 'data' (bytes), 'mime_type', 'filename'
        context: Additional context
        thinking_mode: If True, show model reasoning
    """

    if not client:
        print("Gemini client not initialized - missing API key")
        return None

    try:
        from google.genai import types

        # Build system prompt for file analysis
        system_prompt = """You are MediBot, an expert medical assistant. You are analyzing medical documents and images provided by the user.

## Your Approach:
1. **Analyze the attached files** thoroughly - look for key medical information
2. **Extract important data**: conditions, medications, test results, diagnoses
3. **Summarize clearly** in simple language the user can understand
4. **Provide context** about what the values mean
5. **Suggest follow-up questions** they should ask their doctor

## Guidelines:
- Be thorough but concise
- Highlight any abnormal values or concerns
- Explain medical terms in simple language
- Always recommend consulting a healthcare professional for medical decisions
"""

        if thinking_mode:
            system_prompt += "\n\nShow your thinking process in <thinking>...</thinking> tags before your response."

        # Build content parts
        content_parts = []

        # Add text prompt
        full_prompt = f"Context: {context}\n\n{prompt}" if context else prompt
        content_parts.append(f"{system_prompt}\n\nUser: {full_prompt}")

        # Add file parts
        for f in files:
            try:
                file_part = types.Part.from_bytes(
                    data=f["data"],
                    mime_type=f["mime_type"]
                )
                content_parts.append(file_part)
                print(f"Added file: {f.get('filename', 'unknown')} ({f['mime_type']})")
            except Exception as e:
                print(f"Failed to add file {f.get('filename')}: {e}")

        print(f"Calling Gemini with {len(files)} files (model={LLM_MODEL_ID})")

        response = client.models.generate_content(
            model=LLM_MODEL_ID,
            contents=content_parts,
        )

        # Extract text from response
        response_text = None
        if response.text:
            response_text = response.text
        elif response.parts:
            for part in response.parts:
                if hasattr(part, 'text') and part.text:
                    response_text = part.text
                    break

        if response_text:
            return clean_llm_response(response_text, keep_thinking=thinking_mode)

        return None

    except Exception as e:
        print(f"Error invoking Gemini with files: {e}")
        import traceback
        print(traceback.format_exc())
        return None


def generate_image(prompt: str, width: int = 512, height: int = 512) -> Optional[bytes]:
    """
    Generate an image using Gemini's native image generation.
    Uses gemini-2.5-flash-image model which supports image output.
    Returns raw image bytes.
    """
    if not client:
        print("Gemini client not initialized - missing API key")
        return None

    try:
        enhanced_prompt = (
            "Create a clear, professional medical illustration: "
            f"{prompt}. Style: educational diagram, clean white background, "
            f"anatomically accurate. Preferred size: {width}x{height}."
        )

        print(f"Generating image with Gemini: {IMAGE_MODEL_ID}")

        response = client.models.generate_content(
            model=IMAGE_MODEL_ID,
            contents=enhanced_prompt,
        )

        # Try candidates structure first (new SDK format)
        if hasattr(response, 'candidates') and response.candidates:
            for candidate in response.candidates:
                if hasattr(candidate, 'content') and candidate.content:
                    if hasattr(candidate.content, 'parts'):
                        for part in candidate.content.parts:
                            if hasattr(part, 'inline_data') and part.inline_data:
                                if hasattr(part.inline_data, 'data'):
                                    print("Image generated successfully!")
                                    return part.inline_data.data

        # Fall back to direct parts attribute (old SDK format)
        if hasattr(response, 'parts') and response.parts:
            for part in response.parts:
                if hasattr(part, 'inline_data') and part.inline_data is not None:
                    if hasattr(part.inline_data, 'data'):
                        print("Image generated successfully!")
                        return part.inline_data.data

        print("No image found in Gemini response")
        if hasattr(response, 'text') and response.text:
            print(f"Response text: {response.text[:200]}...")
        return None

    except Exception as e:
        print(f"Error generating image with Gemini: {e}")
        import traceback
        print(traceback.format_exc())
        return None


def extract_treatment_steps(llm_response: str) -> List[Dict[str, str]]:
    """Parse the LLM response to extract individual treatment steps."""
    steps = []

    step_pattern = r'\*?\*?Step\s*(\d+)[:\s]*\*?\*?\s*\[?([^\]\n]+)\]?\*?\*?'
    matches = list(re.finditer(step_pattern, llm_response, re.IGNORECASE))

    for i, match in enumerate(matches):
        step_num = match.group(1)
        title = match.group(2).strip().strip('*[]')

        start_pos = match.end()
        if i + 1 < len(matches):
            end_pos = matches[i + 1].start()
        else:
            next_section = re.search(r'\n\*\*[^S]', llm_response[start_pos:])
            end_pos = start_pos + next_section.start() if next_section else len(llm_response)

        description = llm_response[start_pos:end_pos].strip()
        description = re.sub(r'^\*?\*?\s*', '', description)[:300]

        steps.append({
            'step_number': step_num,
            'title': title,
            'description': description
        })

    return steps


def create_step_visual_guide_prompt(step: Dict[str, str], query: str) -> str:
    """
    Create a 4-panel grid prompt for ONE step.
    Each panel shows a different aspect of the same step.
    """
    query_lower = query.lower()

    # Formal Production-Grade Image Prompt Template
    prompt = f"""Generate a medically informative visual guide using a 2√ó2 grid layout.

Context:
This image explains Step {step['step_number']} of a medical assistance guide.

Step Description:
"{step['title']}: {step['description'][:200]}"

Grid Requirements:
Each panel must visually represent one sub-direction of the same step:

Top-Left Panel:
Show the primary action clearly and safely.

Top-Right Panel:
Show the correct method or technique (posture, tool usage, hand placement).

Bottom-Left Panel:
Show what NOT to do or common mistakes, using clear visual contrast.

Bottom-Right Panel:
Show the expected correct outcome or confirmation state.

Visual Style:
- Clear, instructional, non-graphic
- Neutral medical illustration style
- No blood, gore, or invasive depiction
- High clarity, simple background
- Universally understandable symbols

Restrictions:
- Do not add extra steps
- Do not contradict the step text
- Do not include text-heavy labels
- Avoid realism that may cause distress

Purpose:
This image must act as a complete visual explanation of Step {step['step_number']}.
"""
    return prompt


def process_single_step_image(step: Dict, query: str, query_hash: Optional[str] = None) -> Dict:
    """
    Process a single step: generate a dedicated 4-panel image.
    Includes fallback handling for image generation failures.
    """
    step_number = step['step_number']
    title = step['title']
    description = step['description'][:200]

    # Fallback text structure (Tier 2 degradation)
    fallback_text = {
        'action': f"Primary action for {title}",
        'method': f"How to perform: {description[:80]}...",
        'caution': "Common mistakes to avoid when performing this step.",
        'result': "Expected outcome when done correctly."
    }

    try:
        logger.info("Generating step visual guide", step_number=step_number)

        image_prompt = create_step_visual_guide_prompt(step, query)
        image_bytes = generate_image(image_prompt)
        image_url = None
        image_b64 = None
        image_failed = False
        s3_key = None

        if image_bytes:
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            if query_hash:
                image_url, s3_key = upload_image_to_s3(image_bytes, step_number, query_hash)
        else:
            # Tier 1: Image generation returned None
            image_failed = True
            logger.warning("Image generation returned None", step=step_number)

        return {
            'step_number': step_number,
            'title': title,
            'description': description,
            'image_prompt': image_prompt,
            'image': image_b64,
            'image_url': image_url,
            's3_key': s3_key,  # Store key for URL regeneration
            'is_composite': False,
            'panel_index': None,
            'image_failed': image_failed,
            'fallback_text': fallback_text if image_failed else None
        }

    except Exception as e:
        # Tier 1: Exception during image generation
        logger.error("Error generating step image", step=step_number, error=str(e))
        return {
            'step_number': step_number,
            'title': title,
            'description': description,
            'image_prompt': None,
            'image': None,
            'image_url': None,
            'image_failed': True,
            'fallback_text': fallback_text
        }


def generate_all_step_images(steps: List[Dict], query: str, query_hash: Optional[str] = None) -> List[Dict]:
    """
    Generate images using Step-Aligned Visual Guidance.
    1 step ‚Üí 1 image (4-panel grid explaining that step in depth).

    Time budgeting: Estimates ~3s per image with 5 parallel workers.
    Leaves 60s buffer before Lambda 300s timeout.
    """
    import time as time_module
    TIME_BUDGET_SECONDS = 240  # Leave 60s buffer before Lambda timeout
    ESTIMATED_SECONDS_PER_IMAGE = 3  # With 5 parallel workers

    # Soft limit to prevent timeouts
    MAX_IMAGES = 10

    # Time-based limit: how many images can we afford?
    max_affordable = int(TIME_BUDGET_SECONDS / ESTIMATED_SECONDS_PER_IMAGE)
    effective_limit = min(MAX_IMAGES, max_affordable)

    if len(steps) > effective_limit:
        logger.info("Limiting steps for image generation",
                   original=len(steps),
                   limit=effective_limit,
                   reason="time_budget")
        steps = steps[:effective_limit]

    logger.info("Generating step-aligned images", step_count=len(steps))

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_step = {
            executor.submit(process_single_step_image, step, query, query_hash): step
            for step in steps
        }

        results = []
        for future in concurrent.futures.as_completed(future_to_step):
            result = future.result()
            results.append(result)

    # Sort by step number
    try:
        results.sort(key=lambda x: int(re.sub(r'\D', '', str(x['step_number']))))
    except Exception:
        pass

    return results


def should_generate_images(query: str, response: str) -> bool:
    """Determine if step-by-step images should be generated."""
    visual_keywords = [
        "cpr", "cardiopulmonary", "chest compression", "heimlich",
        "bandage", "wrap", "splint", "immobilize", "position",
        "wound", "cut", "bleeding", "burn", "fracture", "sprain",
        "treat", "treatment", "first aid", "apply", "clean", "dress",
        "choking", "fainting", "unconscious", "recovery position",
        "how to", "steps", "procedure"
    ]

    combined_text = (query + " " + response).lower()
    return any(keyword in combined_text for keyword in visual_keywords)


def detect_medical_topic(query: str) -> Optional[str]:
    """Detect the primary medical topic from the query."""
    query_lower = query.lower()

    topics = {
        "cpr": ["cpr", "cardiopulmonary", "chest compression", "cardiac arrest"],
        "choking": ["choking", "heimlich", "can't breathe", "airway blocked"],
        "bleeding": ["bleeding", "wound", "cut", "blood", "laceration"],
        "burn": ["burn", "burned", "scalded"],
        "fracture": ["fracture", "broken bone", "broken arm", "broken leg"],
        "fainting": ["fainting", "fainted", "unconscious", "passed out"],
        "sprain": ["sprain", "twisted", "ankle", "wrist injury"],
    }

    for topic, keywords in topics.items():
        if any(keyword in query_lower for keyword in keywords):
            return topic

    return None


# Test function
if __name__ == "__main__":
    print("Testing Gemini Client with NEW SDK...")
    print(f"LLM Model: {LLM_MODEL_ID}")
    print(f"Image Model: {IMAGE_MODEL_ID}")

    # Test LLM
    response = invoke_llm("How do I perform CPR on an adult?")
    if response:
        print(f"\nLLM Response:\n{response[:500]}...")

    # Test Image
    image = generate_image("A person performing chest compressions on an adult for CPR")
    if image:
        print(f"\nImage generated: {len(image)} bytes")
